{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a4df227",
   "metadata": {},
   "source": [
    "# Similarity search with Milvus vector index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29b79c",
   "metadata": {},
   "source": [
    "In this tutorial, we demonstrate the integration of Milvus vector store to EvaDB by conducting an image-level similarity search on a collection of Reddit images. We employ the classic `SIFT` feature, which is  to identify images with a strikingly similar appearance (image-level pipeline).\n",
    "\n",
    "Within EvaDB, multiple vector stores are supported, including but not limited to `FAISS` and `QDRANT`. With the  integration of `MILVUS` as a vector store, we enrich our selection of vector stores for building indexes. This enhancement allows us to tailor our choice of vector stores to specific application requirements, taking full advantage of the diverse functionalities they offer.\n",
    "\n",
    "Note: This tutorial is a modified version of the first part of https://github.com/georgia-tech-db/evadb/blob/staging/tutorials/11-similarity-search-for-motif-mining.ipynb, which is created for conducting image-level similarity search using `FAISS`. We have adapted the content to demonstrate the same search functionality using `MILVUS`. While the core principles of similarity search remain the same, this tutorial focuses on implementing them with `MILVUS`, providing you with an alternative approach to achieving similar results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b1674e",
   "metadata": {},
   "source": [
    "### Connect to EvaDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fcb8ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evadb\n",
    "cursor = evadb.connect().cursor()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f4144",
   "metadata": {},
   "source": [
    "### Download reddit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527ec1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘reddit-images.zip’ already there; not retrieving.\n",
      "Archive:  reddit-images.zip\n",
      "warning:  stripped absolute path spec from /\n",
      "mapname:  conversion of  failed\n",
      " extracting: reddit-images/g348_d7jgzgf.jpg  \n",
      " extracting: reddit-images/g348_d7jphyc.jpg  \n",
      " extracting: reddit-images/g348_d7ju7dq.jpg  \n",
      " extracting: reddit-images/g348_d7jhhs3.jpg  \n",
      " extracting: reddit-images/g1074_d4n1lmn.jpg  \n",
      " extracting: reddit-images/g1074_d4mxztt.jpg  \n",
      " extracting: reddit-images/g1074_d4n60oy.jpg  \n",
      " extracting: reddit-images/g1074_d4n6fgs.jpg  \n",
      " extracting: reddit-images/g1190_cln9xzr.jpg  \n",
      " extracting: reddit-images/g1190_cln97xm.jpg  \n",
      " extracting: reddit-images/g1190_clna260.jpg  \n",
      " extracting: reddit-images/g1190_clna2x2.jpg  \n",
      " extracting: reddit-images/g1190_clna91w.jpg  \n",
      " extracting: reddit-images/g1190_clnad42.jpg  \n",
      " extracting: reddit-images/g1190_clnajd7.jpg  \n",
      " extracting: reddit-images/g1190_clnapoy.jpg  \n",
      " extracting: reddit-images/g1190_clnarjl.jpg  \n",
      " extracting: reddit-images/g1190_clnavnu.jpg  \n",
      " extracting: reddit-images/g1190_clnbalu.jpg  \n",
      " extracting: reddit-images/g1190_clnbf07.jpg  \n",
      " extracting: reddit-images/g1190_clnc4uy.jpg  \n",
      " extracting: reddit-images/g1190_clncot0.jpg  \n",
      " extracting: reddit-images/g1190_clndsnu.jpg  \n",
      " extracting: reddit-images/g1190_clnce4b.jpg  \n",
      " extracting: reddit-images/g1209_ct65pvl.jpg  \n",
      " extracting: reddit-images/g1209_ct66erw.jpg  \n",
      " extracting: reddit-images/g1209_ct67oqk.jpg  \n",
      " extracting: reddit-images/g1209_ct6a0g5.jpg  \n",
      " extracting: reddit-images/g1209_ct6bf1n.jpg  \n",
      " extracting: reddit-images/g1418_cj3o1h6.jpg  \n",
      " extracting: reddit-images/g1418_cj3om3h.jpg  \n",
      " extracting: reddit-images/g1418_cj3qysz.jpg  \n",
      " extracting: reddit-images/g1418_cj3r4gw.jpg  \n",
      " extracting: reddit-images/g1418_cj3z7jw.jpg  \n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://www.dropbox.com/scl/fo/fcj6ojmii0gw92zg3jb2s/h\\?dl\\=1\\&rlkey\\=j3kj1ox4yn5fhonw06v0pn7r9 -O reddit-images.zip\n",
    "!unzip -o reddit-images.zip -d reddit-images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8c9917",
   "metadata": {},
   "source": [
    "### Load all images into evadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9bca7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number of loaded IMAGE: 34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "0  Number of loaded IMAGE: 34"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.query(\"DROP TABLE IF EXISTS reddit_dataset;\").df()\n",
    "cursor.query(\"LOAD IMAGE 'reddit-images/*.jpg' INTO reddit_dataset;\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743684c",
   "metadata": {},
   "source": [
    "### Register a SIFT FeatureExtractor \n",
    "It uses `kornia` library to extract sift features for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49496e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Function SiftFeatureExtractor added to the dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Function SiftFeatureExtractor added to the dat..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.query(\"DROP FUNCTION IF EXISTS SiftFeatureExtractor;\").df()\n",
    "cursor.query(\"\"\"\n",
    "    CREATE FUNCTION SiftFeatureExtractor\n",
    "    IMPL '../evadb/functions/sift_feature_extractor.py'\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1101ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of which image gets the most votes\n",
    "from collections import Counter\n",
    "vote = Counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a1e73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T04:14:02.011536Z",
     "iopub.status.busy": "2023-05-10T04:14:02.011425Z",
     "iopub.status.idle": "2023-05-10T04:14:02.015115Z",
     "shell.execute_reply": "2023-05-10T04:14:02.014808Z"
    }
   },
   "source": [
    "## Image-level similarity search pipeline. \n",
    "This pipeline creates one vector per image. Next, we should breakdown steps how we build the index and search similar vectors using the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d85e3fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10-11-2023 19:16:18 WARNING[drop_object_executor:drop_object_executor.py:_handle_drop_index:0113] Index reddit_sift_image_index does not exist, therefore cannot be dropped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Index reddit_sift_image_index successfully add...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Index reddit_sift_image_index successfully add..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Create index for the entire image\n",
    "cursor.query(\"\"\"DROP INDEX IF EXISTS reddit_sift_image_index\"\"\").df()\n",
    "cursor.query(\"\"\"\n",
    "    CREATE INDEX reddit_sift_image_index \n",
    "    ON reddit_dataset (SiftFeatureExtractor(data)) \n",
    "    USING MILVUS\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54cfe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Search similar vectors\n",
    "response = cursor.query(\"\"\"\n",
    "    SELECT name FROM reddit_dataset ORDER BY\n",
    "    Similarity(\n",
    "      SiftFeatureExtractor(Open('reddit-images/g1074_d4mxztt.jpg')),\n",
    "      SiftFeatureExtractor(data)\n",
    "    )\n",
    "    LIMIT 5\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68734588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'reddit-images/g1074_d4mxztt.jpg': 1, 'reddit-images/g348_d7ju7dq.jpg': 1, 'reddit-images/g1209_ct6bf1n.jpg': 1, 'reddit-images/g1190_cln9xzr.jpg': 1, 'reddit-images/g1190_clna2x2.jpg': 1})\n"
     ]
    }
   ],
   "source": [
    "#3. Update votes\n",
    "for i in range(len(response)):\n",
    "    vote[response[\"name\"][i]] += 1\n",
    "print(vote)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
